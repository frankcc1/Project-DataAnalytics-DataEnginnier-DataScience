
# ğŸš€ Proyecto de IngenierÃ­a de Datos en Azure + Clustering  

Este proyecto es una soluciÃ³n de canalizaciÃ³n de ingenierÃ­a de datos para un problema empresarial inventado, creado para ayudarme en mi aprendizaje en la comprensiÃ³n de la canalizaciÃ³n de datos y segmentaciÃ³n de clientes.  

![image alt](https://github.com/frankcc1/Project-DataAnalytics-DataEnginnier-DataScience/blob/b0fff8bced6d17f41c7f2a99861fda100be9becc/Databricks/image.png)
![image alt](https://github.com/frankcc1/Project-DataAnalytics-DataEnginnier-DataScience/blob/8d917dde94ea2d057254f4dcad9dcf34f94ed846/Databricks/image.png)

## ğŸ“Œ **DescripciÃ³n general del proyecto**  
Este proyecto aborda una necesidad empresarial crÃ­tica mediante la creaciÃ³n de una canalizaciÃ³n de datos integral en Azure. El objetivo es extraer datos de clientes, ventas, productos y sucursales de una base de datos SQL local, transformarlos en la nube y aplicar tÃ©cnicas de Machine Learning en la agrupaciÃ³n de clientes para generar informaciÃ³n procesable a travÃ©s de un panel de Power BI.  

El panel resaltarÃ¡ los indicadores clave de rendimiento (KPI) relacionados con:  
- Ventas por categorÃ­a de producto  
- Ventas de carÃ¡cter mensual y anual  
- Filtros por fecha, categorÃ­a de producto y sucursal  

## ğŸ¯ **Requisitos empresariales**  
La empresa ha identificado una brecha en comprender mÃ¡s a sus clientes (especÃ­ficamente por la frecuencia y recencia en las compras). Los requisitos clave incluyen:  

âœ”ï¸ **Ventas por sucursal y categorÃ­a de producto**: un panel que muestre el total de productos vendidos, los ingresos totales por ventas y una divisiÃ³n por sucursal entre los clientes.  

âœ”ï¸ **Filtrado de datos**: capacidad para filtrar los datos por categorÃ­a de producto, sucursal y fecha.  

âœ”ï¸ **Interfaz fÃ¡cil de usar**: las partes interesadas deben tener acceso a una interfaz intuitiva para realizar consultas.  

## âš™ï¸ **DescripciÃ³n general de la soluciÃ³n**  
Para cumplir con estos requisitos, la soluciÃ³n se divide en los siguientes componentes:  

### ğŸ”„ **IngestiÃ³n de datos**  
âœ”ï¸ Extraer datos de clientes, ventas, productos, categorÃ­as y sucursales de una base de datos SQL local.  
âœ”ï¸ Cargar los datos en **Azure Data Lake Storage (ADLS)** mediante **Azure Data Factory (ADF)**.  

### ğŸ” **TransformaciÃ³n de datos**  
âœ”ï¸ Usar **Azure Databricks** para limpiar y transformar los datos.  
âœ”ï¸ Organizar los datos en capas **Bronze y Silver** para datos sin procesar y limpios, respectivamente.  

### ğŸ“Š **Carga de datos e informes**  
âœ”ï¸ Cargar los datos transformados en **Azure Synapse Analytics**.  
âœ”ï¸ Crear un **panel de Power BI** para visualizar los datos, permitiendo a las partes interesadas explorar las ventas y los insights demogrÃ¡ficos.  

### â³ **AutomatizaciÃ³n**  
âœ”ï¸ Programar la canalizaciÃ³n para que se ejecute **diariamente**, garantizando que los datos y los informes estÃ©n siempre actualizados.  

## ğŸ› ï¸ **Pila de tecnologÃ­a**  
- **Azure Data Factory (ADF)**: OrquestaciÃ³n del movimiento y transformaciÃ³n de datos.  
- **Azure Data Lake Storage (ADLS)**: Almacenamiento de datos procesados y sin procesar.  
- **Azure Databricks**: TransformaciÃ³n y procesamiento de datos.  
- **Azure Synapse Analytics**: Almacenamiento de datos y anÃ¡lisis basado en SQL.  
- **Power BI**: VisualizaciÃ³n y generaciÃ³n de informes.  
- **Azure Key Vault**: GestiÃ³n segura de credenciales y secretos.  
- **SQL Server (local)**: Fuente de los datos de ventas, clientes, productos y sucursales.  

## ğŸ—ï¸ **Instrucciones de configuraciÃ³n**  

### ğŸ”§ **Requisitos previos**  
âœ”ï¸ Una cuenta de Azure con crÃ©ditos suficientes.  
âœ”ï¸ Acceso a una base de datos local de **SQL Server**.  

### ğŸš€ **Paso 1: ConfiguraciÃ³n del entorno de Azure**  
âœ”ï¸ **Crear un grupo de recursos**: Configurar un nuevo grupo de recursos en Azure.  
âœ”ï¸ **Aprovisionar servicios**:  
   - Crear una instancia de **Azure Data Factory**.  
   - Configurar **Azure Data Lake Storage** con contenedores Bronze, Silver y Gold.  
   - Configurar un Ã¡rea de trabajo de **Azure Databricks** y un Ã¡rea de trabajo de **Synapse Analytics**.  
   - Configurar **Azure Key Vault** para la administraciÃ³n de secretos.  

### ğŸ“¥ **Paso 2: Ingesta de datos**  
âœ”ï¸ **Configurar SQL Server**: Instalar **SQL Server** y **SQL Server Management Studio (SSMS)**. Restaurar la base de datos compartida.  
âœ”ï¸ **Ingerir datos con ADF**: Crear canalizaciones en **ADF** para copiar datos de **SQL Server** a la capa de **bronce** en **ADLS**.  

### ğŸ”„ **Paso 3: TransformaciÃ³n de datos**  
âœ”ï¸ **Montar Data Lake en Databricks**: Configurar **Databricks** para acceder a **ADLS**.  
âœ”ï¸ **Transformar datos**:  
   - Utilizar los cuadernos de **Databricks** para limpiar y agregar los datos, moviÃ©ndolos de **Bronze a Silver**.  
   - **Clustering**: Extraer data del contenedor **Silver** para el anÃ¡lisis correspondiente. *(Repositorio disponible)*.  

### ğŸ“¤ **Paso 4: Carga de datos e informes**  
âœ”ï¸ **Cargar datos en Synapse**: Configurar un grupo de SQL en **Synapse** y cargar los datos para su anÃ¡lisis.  
âœ”ï¸ **Crear un panel de Power BI**: Conectar **Power BI** a **Synapse** y generar visualizaciones basadas en los requisitos comerciales.  

### â³ **Paso 5: AutomatizaciÃ³n y supervisiÃ³n**  
âœ”ï¸ **Programar canalizaciones**: Usar **ADF** para programar las canalizaciones de datos de ejecuciÃ³n diaria.  
âœ”ï¸ **Supervisar ejecuciones**: Utilizar herramientas de monitoreo en **ADF** y **Synapse** para garantizar la correcta ejecuciÃ³n de las canalizaciones.  

### ğŸ”’ **Paso 6: Seguridad y gobernanza**  
âœ”ï¸ **Administrar el acceso**: Configurar el **Control de Acceso Basado en Roles (RBAC)** mediante **Azure Entra ID**.  

### âœ… **Paso 7: Prueba**  
âœ”ï¸ **Activar y probar canales**: Insertar nuevos registros en la base de datos SQL y verificar que el canal se ejecute correctamente, reflejando los cambios en el **panel de Power BI**.  

## ğŸ¯ **ConclusiÃ³n**  
Este proyecto proporciona una **soluciÃ³n integral** para comprender la **demografÃ­a de los clientes** y su impacto en las ventas. La automatizaciÃ³n garantiza que las partes interesadas siempre tengan acceso a **datos actualizados** y procesables.
